{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"djfedos-search djfedos-search is a python library that implements a quick search of a token by its prefix. Purpose of the project First of all it can be used as an engine behind the user input suggestion, like in searching engines. Here you can try it out in this role. How does it work? How to run demo in local environment? How to use the library? Tests Benchmarks Authors This library and its demo web app is written by Fedor Ivashchenko under the guidance of Yair Dar","title":"About"},{"location":"#djfedos-search","text":"djfedos-search is a python library that implements a quick search of a token by its prefix.","title":"djfedos-search"},{"location":"#purpose-of-the-project","text":"First of all it can be used as an engine behind the user input suggestion, like in searching engines. Here you can try it out in this role. How does it work? How to run demo in local environment? How to use the library? Tests Benchmarks","title":"Purpose of the project"},{"location":"#authors","text":"This library and its demo web app is written by Fedor Ivashchenko under the guidance of Yair Dar","title":"Authors"},{"location":"benchmarks/","text":"To benchmark performance of the library in different scenarios, use test_benchmarks.py with pytest module. There are several functions for benchmarking that support semi-automated workflow. test_benchmark_load_db() measures the performance of loading tokens to the database from the text file. It has the following parameters: num_lines:int : number of lines (tokens) in a text file that's generated on every benchmark cycle. max_length:int : length of a single token in characters. all the generated tokens have the same length, that is also a maximum length, in order to reproduce the worst case scenario. cycles:int : number of benchmark cycles to average out any fluctuations of its results. result_path:str : path to the file with benchmark results. It's recommended to save results in .csv file. test_benchmark_get_suggestions_limits() measures the performance of getting tokens from the database with a given limit on maximum amount of output tokens. The prefix is set to an empty string to maximize possible token output. It has the following parameters: limit:int : the main parameter of the test, it sets a maximum amount of tokens that the engine will output. num_lines:int : number of lines (tokens) in a text file that's generated on every benchmark cycle. max_length:int : length of a single token in characters. all the generated tokens have the same length, that is also a maximum length, in order to reproduce the worst case scenario. cycles:int : number of benchmark cycles to average out any fluctuations of its results. result_path:str : path to the file with benchmark results. It's recommended to save results in .csv file. prefix_length=0 in this case is used only to output the results into a .csv file. The prefix length in this test is hardcoded to be zero anyway, so it's recommended not to edit this parameter and leave it as it is. test_benchmark_get_suggestions_prefix() this benchmark emulates a pretty unrealistic worst case scenario. It generates a token base with strings of a single character 'a'. Then it measures the time that it takes to fetch all the suitable tokens with prefixes consisting of the same character 'a'. It cycles through prefix length values from zero to (prefix_length - 1). prefix_length:int : maximum prefix length. num_lines:int : number of lines (tokens) in a text file that's generated on every benchmark cycle. limit:int : maximum amount of tokens that the engine will output. cycles:int : number of benchmark cycles to average out any fluctuations of its results. result_path:str : path to the file with benchmark results. It's recommended to save results in .csv file. test_plot_benchmarks() This method allows plotting benchmark results as a graph from the .csv file. It's useful when you make several benchmark runs with different parameters. result_path:str: path to the .csv file with benchmark results columns:List(str): columns with data to plot in ['x','y'] form, where 'x' is the name of horizontal axis data and 'y' is the name of vertical axis data.","title":"Benchmarks"},{"location":"benchmarks/#test_benchmark_load_db","text":"measures the performance of loading tokens to the database from the text file. It has the following parameters: num_lines:int : number of lines (tokens) in a text file that's generated on every benchmark cycle. max_length:int : length of a single token in characters. all the generated tokens have the same length, that is also a maximum length, in order to reproduce the worst case scenario. cycles:int : number of benchmark cycles to average out any fluctuations of its results. result_path:str : path to the file with benchmark results. It's recommended to save results in .csv file.","title":"test_benchmark_load_db()"},{"location":"benchmarks/#test_benchmark_get_suggestions_limits","text":"measures the performance of getting tokens from the database with a given limit on maximum amount of output tokens. The prefix is set to an empty string to maximize possible token output. It has the following parameters: limit:int : the main parameter of the test, it sets a maximum amount of tokens that the engine will output. num_lines:int : number of lines (tokens) in a text file that's generated on every benchmark cycle. max_length:int : length of a single token in characters. all the generated tokens have the same length, that is also a maximum length, in order to reproduce the worst case scenario. cycles:int : number of benchmark cycles to average out any fluctuations of its results. result_path:str : path to the file with benchmark results. It's recommended to save results in .csv file. prefix_length=0 in this case is used only to output the results into a .csv file. The prefix length in this test is hardcoded to be zero anyway, so it's recommended not to edit this parameter and leave it as it is.","title":"test_benchmark_get_suggestions_limits()"},{"location":"benchmarks/#test_benchmark_get_suggestions_prefix","text":"this benchmark emulates a pretty unrealistic worst case scenario. It generates a token base with strings of a single character 'a'. Then it measures the time that it takes to fetch all the suitable tokens with prefixes consisting of the same character 'a'. It cycles through prefix length values from zero to (prefix_length - 1). prefix_length:int : maximum prefix length. num_lines:int : number of lines (tokens) in a text file that's generated on every benchmark cycle. limit:int : maximum amount of tokens that the engine will output. cycles:int : number of benchmark cycles to average out any fluctuations of its results. result_path:str : path to the file with benchmark results. It's recommended to save results in .csv file.","title":"test_benchmark_get_suggestions_prefix()"},{"location":"benchmarks/#test_plot_benchmarks","text":"This method allows plotting benchmark results as a graph from the .csv file. It's useful when you make several benchmark runs with different parameters. result_path:str: path to the .csv file with benchmark results columns:List(str): columns with data to plot in ['x','y'] form, where 'x' is the name of horizontal axis data and 'y' is the name of vertical axis data.","title":"test_plot_benchmarks()"},{"location":"how_does_it_wrok/","text":"First it takes a list of words as an input. It turns this list into a trie aka a prefix tree. Then it takes a prefix (any given string of characters) as an input and returns the words (aka tokens) from the trie that start with this prefix. More details The library itself is in lib_search_sdk.py file. It's self-contained, it doesn't need any other files from the repository in order to work. It also doesn't import any python modules. All the additional files are there for testing, benchmarking, documentation and demonstration purposes. The input format for words (aka tokens) is a text file, one word per line. The input format for prefix is string. Given an empty string as a prefix the library will output all the words stored in its prefix tree, though only if limit is set to None . limit is an optional parameter, by default it's set to 10. It defines the maximum amount of words that the library will return for a given prefix. Limit can be an integer number or None . When limit is set to None , the library outputs all the words that start with a given prefix. For even more details you're always welcome to read the source code and ask me any questions.","title":"How does it work"},{"location":"how_does_it_wrok/#more-details","text":"The library itself is in lib_search_sdk.py file. It's self-contained, it doesn't need any other files from the repository in order to work. It also doesn't import any python modules. All the additional files are there for testing, benchmarking, documentation and demonstration purposes. The input format for words (aka tokens) is a text file, one word per line. The input format for prefix is string. Given an empty string as a prefix the library will output all the words stored in its prefix tree, though only if limit is set to None . limit is an optional parameter, by default it's set to 10. It defines the maximum amount of words that the library will return for a given prefix. Limit can be an integer number or None . When limit is set to None , the library outputs all the words that start with a given prefix. For even more details you're always welcome to read the source code and ask me any questions.","title":"More details"},{"location":"how_to_run_local_demo/","text":"There is a FastAPI-based web API in fapi_server.py . While running, it will reply to the queries. Make sure that the requirements are satisfied and run it. Then open http://0.0.0.0:18000 in a browser (make sure that JSON content gets displayed properly; in Chrome it can be achieved with JSON Viewer extension ). Load an example list of tokens by clicking the \"recreate\" link. Now you can try other links, especially \"query\" with any prefixes you like. You can as well open js_web_ui/index.html in a browser and try out a demo suggestion web app, identical to this one . To try out the library with a decent example base of tokens in a convenient web interface you can also launch neat_pywebio_app.py .","title":"How to run demo in local environment"},{"location":"how_to_use/","text":"The library itself is in the lib_search_sdk.py file. In order to use it, import it: import lib_search_sdk The external API of lib_search_sdk has two main methods: 1. load_db(path:str=None) To load a list of words, pass a path to the .txt file containing one word per line. This function returns a dict, that is the database to search through. Example: test_token_db = load_db('tests/1200_tokens.txt') 2. get_suggestions(mdb:dict, prefix:str, limit:int=10) To get suggestions, pass a token db returned by load_db() as a first argument, a prefix as a second argument and optionally the limit, which is the maximum amount of suggestions you want to get from this function. By default the limit is set to 10. If you want to get all the suggestions, pass None as a limit. Examples: suggestions = get_suggestions(test_token_db, 'flo') suggestions = get_suggestions(test_token_db, 'ma', None) suggestions = get_suggestions(test_token_db, 'do', 3) There is also an additional method: 3. add_to_db(mdb:dict, token:str) To add a token to the existing db, pass the db as a first argument and a token as a second. Example: add_to_db(test_token_db, 'acidity') if this token is already in the db, this function will return False , else it will add a token and return True .","title":"How to use the library"},{"location":"how_to_use/#1-load_dbpathstrnone","text":"To load a list of words, pass a path to the .txt file containing one word per line. This function returns a dict, that is the database to search through. Example: test_token_db = load_db('tests/1200_tokens.txt')","title":"1. load_db(path:str=None)"},{"location":"how_to_use/#2-get_suggestionsmdbdict-prefixstr-limitint10","text":"To get suggestions, pass a token db returned by load_db() as a first argument, a prefix as a second argument and optionally the limit, which is the maximum amount of suggestions you want to get from this function. By default the limit is set to 10. If you want to get all the suggestions, pass None as a limit. Examples: suggestions = get_suggestions(test_token_db, 'flo') suggestions = get_suggestions(test_token_db, 'ma', None) suggestions = get_suggestions(test_token_db, 'do', 3) There is also an additional method:","title":"2. get_suggestions(mdb:dict, prefix:str, limit:int=10)"},{"location":"how_to_use/#3-add_to_dbmdbdict-tokenstr","text":"To add a token to the existing db, pass the db as a first argument and a token as a second. Example: add_to_db(test_token_db, 'acidity') if this token is already in the db, this function will return False , else it will add a token and return True .","title":"3. add_to_db(mdb:dict, token:str)"},{"location":"tests/","text":"This library comes with two sets of tests. Use pytest to run them. test_lib_search_sdk.py contains unit tests. This is the main set of tests. It ensures that the crucial functions work as expected. test_lib_search_sdk_custom_set.py contains additional tests for bugs that were discovered manually. Lists of tokens for tests are in the tests folder. There is also a test for FastAPI server in test_fapi_server.py . Those three tests run automatically on every commit push to the GitHub repository . There is an additional tool called test_lib_search_sdk_manual.py that allows convenient manual testing.","title":"Tests"}]}